{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c5ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc1aef2",
   "metadata": {},
   "source": [
    "# Ultrasound imaging simulation\n",
    "\n",
    "Use NDK to simulate the image captured by an ultrasound transducer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm.notebook\n",
    "\n",
    "import neurotechdevkit as ndk\n",
    "from neurotechdevkit.sources import PhasedArraySource2D\n",
    "from neurotechdevkit.scenarios.built_in import Scenario3\n",
    "\n",
    "# Imaging modules\n",
    "from neurotechdevkit.imaging import demodulate, beamform, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3361300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario parameters\n",
    "SPEED_OF_SOUND_WATER = 1500  # meters per second\n",
    "\n",
    "# Plane-wave pulse parameters\n",
    "TONE_CENTER_FREQUENCY = 0.5e6  # Hz\n",
    "TILT_ANGLES_DEG = np.linspace(start=-10, stop=10, endpoint=True, num=5)  # Plane-wave pulses\n",
    "\n",
    "# Phased array transducer parameters\n",
    "ARRAY_PITCH=300e-6\n",
    "ARRAY_ELEMENT_WIDTH=270e-6\n",
    "ARRAY_NUM_ELEMENTS=128\n",
    "TRANSDUCER_6DB_PULSE_ECHO_FRACTIONAL_BANDWIDTH = 0.5  # transmit/receive frequency bandwidth as a fraction of center frequency\n",
    "\n",
    "# Simulation parameters - choosing somewhat arbitrary values\n",
    "SAMPLING_POINTS_PER_PERIOD = 24\n",
    "\n",
    "RANDOM_SEED = 58295  # Use if we need the specific function to be deterministic\n",
    "rng = np.random.default_rng(seed=58295)  # Use if we only need the notebook to be deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c6428",
   "metadata": {},
   "source": [
    "## Define a scenario.\n",
    "\n",
    "Ultrasound imaging measures the scattering of sound waves, which occur due to changes in acoustic impedance (speed and density). In normal tissue, these changes occur across different scales. Large tissue boundaries cause specular scattering, and microscopic heterogeneities cause diffuse scattering. \n",
    "\n",
    "To mimic these properties, we create ultrasound phantoms that are similarly heterogenous across different scales. Their bulk acoustic impedance differs from the background medium (water), and their within-phantom impednances also vary at small scales.\n",
    "\n",
    "For the transducer, we choose a phased array that can both steer ultrasonic waves and record independently at multiple elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8d92d",
   "metadata": {},
   "source": [
    "We visualize the scenario layout with the material masks and then visualize the acoustic properties that affect wave scattering and propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac808c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scenario(tilt_angle: float = 0.0) -> Scenario3:\n",
    "    \"\"\"Helper function to initialize scenario with different tilt angles.\"\"\"\n",
    "    scenario = Scenario3()\n",
    "    scenario.center_frequency = TONE_CENTER_FREQUENCY\n",
    "    source_position = np.array([0.01, 0.0])\n",
    "    unit_direction = np.array([1.0, 0.0])\n",
    "\n",
    "    source = PhasedArraySource2D(\n",
    "        position=source_position,\n",
    "        direction=unit_direction,\n",
    "        num_elements=ARRAY_NUM_ELEMENTS,\n",
    "        num_points=ARRAY_NUM_ELEMENTS * 4,\n",
    "        tilt_angle=tilt_angle,\n",
    "        # Unfocused source for plane-wave\n",
    "        focal_length=np.inf,\n",
    "        pitch=ARRAY_PITCH,\n",
    "        element_width=ARRAY_ELEMENT_WIDTH,\n",
    "    )\n",
    "    scenario.sources = [source]\n",
    "    # Place point receivers at the transducer sources\n",
    "    scenario.receiver_coords = source.element_positions\n",
    "    scenario.make_grid()\n",
    "    scenario.compile_problem()\n",
    "    return scenario\n",
    "\n",
    "scenario = create_scenario()\n",
    "scenario.render_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2012c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relevant material metrics\n",
    "# vp - speed of sound\n",
    "# rho - density\n",
    "# alpha - attenuation\n",
    "fig,axs = plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "for idx, attribute in enumerate([\"vp\", \"rho\", \"alpha\"]):\n",
    "    im = axs[idx].imshow(getattr(scenario.problem.medium, attribute).data)\n",
    "    plt.colorbar(im, ax=axs[idx])\n",
    "    axs[idx].set_title(attribute)\n",
    "    axs[idx].set_xlabel(\"y [a.u.]\")\n",
    "    axs[idx].set_ylabel(\"x [a.u.]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af933ab2",
   "metadata": {},
   "source": [
    "# Transmit ultrasonic plane waves\n",
    "We run multiple NDK simulations, each sending an ultrasonic plane wave at the phantoms at different angles.\n",
    "Each echo provides a low-resolution image of the target object. By summing the complex-valued images, the low-resolution image's phases cancel out and create a higher-resolution \"compound\" image.\n",
    "\n",
    "By the way, I'm using the terms pulse/echo/plane-wave somewhat interchangeably, but more specifically pulse=`transmitted ultrasonic wave`, echo=`the sensor signals received from a given pulse`, and plane-wave=`a specific kind of pulse where the wavefront is a plane/line`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd992623",
   "metadata": {},
   "source": [
    "Let's first visualize the plane wave at the default tilt angle (0&deg;)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c105f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = create_scenario().simulate_steady_state()\n",
    "result.render_steady_state_amplitudes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8cc1a1",
   "metadata": {},
   "source": [
    "We can see that the plane wave sonicates a large area of the medium, including the center phantom and (to a lesser extent) the phantom on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631cd9a7",
   "metadata": {},
   "source": [
    "# Multi-plane-wave transmission\n",
    "Now, let's send several plane waves from the transducer and measure the reflected/scattered acoustic waves.\n",
    "We can then compound the different plane waves to improve the spatial resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: simulate long enough for ultrasound scattering reflection\n",
    "def calc_simulation_time(scenario: Scenario3):\n",
    "    simulation_time = ndk.scenarios._time.select_simulation_time_for_pulsed(\n",
    "        grid=scenario.grid,\n",
    "        materials=scenario.materials,\n",
    "        delay=ndk.scenarios._time.find_largest_delay_in_sources(scenario.sources),\n",
    "    )\n",
    "    # Run pulse for twice the standard simulation time to allow for reflections\n",
    "    return 2 * simulation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send several plane waves from the transducer and measure the reflected/scattered acoustic waves\n",
    "# We can then compound the different plane waves to improve the spatial resolution\n",
    "\n",
    "results = [None] * len(TILT_ANGLES_DEG)\n",
    "# keep track of the tx delays used\n",
    "element_delays_list = [None] * len(TILT_ANGLES_DEG)\n",
    "\n",
    "for idx, tilt_angle in enumerate(tqdm.notebook.tqdm(TILT_ANGLES_DEG, desc=\"Simulating pulses\", unit=\"pulse\")):\n",
    "    # Current limitation of NDK: need to re-generate scenario to simulate a new pulse\n",
    "    # https://github.com/agencyenterprise/neurotechdevkit/issues/108\n",
    "    scenario = create_scenario(tilt_angle=tilt_angle)\n",
    "    # Get the element delays (set by the tilt angle)\n",
    "    element_delays_list[idx] = scenario.sources[0].element_delays\n",
    "    results[idx] = scenario.simulate_pulse(\n",
    "        points_per_period=SAMPLING_POINTS_PER_PERIOD,\n",
    "        simulation_time=calc_simulation_time(scenario),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22de77f5",
   "metadata": {},
   "source": [
    "## Visualizing received (simulated) signals\n",
    "\n",
    "In a real imaging situation, we usually only have access to the RF signals measured at the ultrasound sensor elements; we don't know what's in the grid and can't access the full wavefield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5578aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The receivers at N sensor elements give us data traces of [N, num_fast_time_samples]\n",
    "assert results[0].traces.data.shape == (\n",
    "    ARRAY_NUM_ELEMENTS,\n",
    "    len(results[0].traces.time.grid)\n",
    ")\n",
    "time_steps = [result.traces.time.step for result in results]\n",
    "np.testing.assert_array_equal(time_steps[0], time_steps)\n",
    "freq_sampling = TONE_CENTER_FREQUENCY * SAMPLING_POINTS_PER_PERIOD\n",
    "assert np.allclose(time_steps[0], 1 / freq_sampling)\n",
    "\n",
    "print(\"Traces shape:\", results[0].traces.data.shape)\n",
    "print(\"Time grid:\", results[0].traces.time.grid)\n",
    "print(\"Sampling frequency [Hz]: {:.2e}\".format(freq_sampling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b3878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad RF signals to longest length, in case they are not all the same length\n",
    "rf_signal_lengths = [len(result.traces.time.grid) for result in results]\n",
    "rf_signal_max_len = max(rf_signal_lengths)\n",
    "rf_signal_max_len_idx = np.argmax(rf_signal_lengths)\n",
    "time = results[rf_signal_max_len_idx].traces.time.grid\n",
    "\n",
    "# Shape: [num_fast_time_samples, num_elements, num_pulses]\n",
    "rf_signals = np.zeros(\n",
    "    (rf_signal_max_len, ARRAY_NUM_ELEMENTS, len(results)),\n",
    "    dtype=float,\n",
    ")\n",
    "for pulse_idx, result in enumerate(results):\n",
    "    rf_signals[:rf_signal_lengths[pulse_idx], :, pulse_idx] = result.traces.data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cecf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data at the beginning of each pulse simply contains the transmitted pulse,\n",
    "# so let's remove it from the raw-data visualizations to prevent it from overwhelming the reflected image.\n",
    "extra_buffer_fraction = 0.05\n",
    "array_element_positions = scenario.sources[0].element_positions\n",
    "distance = np.linalg.norm(array_element_positions.max() - array_element_positions.min())\n",
    "\n",
    "for pulse_idx, element_delays in enumerate(element_delays_list):\n",
    "    max_time_delay = element_delays.max()\n",
    "    last_invalid_time = (1 + extra_buffer_fraction) * (distance / SPEED_OF_SOUND_WATER + max_time_delay)\n",
    "    valid_time_mask = time > last_invalid_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51002b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VISUALIZE = 8\n",
    "channel_idxs = rng.integers(ARRAY_NUM_ELEMENTS, size=NUM_VISUALIZE)\n",
    "pulse_idxs = rng.integers(len(TILT_ANGLES_DEG), size=NUM_VISUALIZE)\n",
    "\n",
    "rf_signal_visualize = rf_signals[:, channel_idxs, pulse_idxs]\n",
    "\n",
    "# Plot with some offsets\n",
    "CHANNEL_OFFSET = 1000\n",
    "_ = plt.plot(\n",
    "    time[valid_time_mask] * 1e3,\n",
    "    rf_signal_visualize[valid_time_mask] + np.linspace(-0.5, 0.5, num=NUM_VISUALIZE, endpoint=True) * NUM_VISUALIZE * CHANNEL_OFFSET,\n",
    "    label=[f\"channel-{channel_idx} echo-{echo_idx}\" for (channel_idx, echo_idx) in zip(channel_idxs, pulse_idxs)],\n",
    ")\n",
    "_ = plt.legend()\n",
    "_ = plt.title(\"Example radiofrequency signals (RF)\")\n",
    "_ = plt.xlabel(\"time [ms]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d904602",
   "metadata": {},
   "source": [
    "Plotting across elements (for a single shot) shows the typical hyperbolas for each scatterer (object). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse_idx = rng.integers(len(TILT_ANGLES_DEG))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(\n",
    "    rf_signals[valid_time_mask, :, pulse_idx] + np.arange(ARRAY_NUM_ELEMENTS) * CHANNEL_OFFSET,\n",
    "    time[valid_time_mask] * 1000,\n",
    "    color='k',\n",
    ")\n",
    "ax.set_title(f\"echo {pulse_idx}\")\n",
    "ax.set_xticklabels([])  # We added values for offset, so values don't mean anything\n",
    "ax.set_ylabel(\"time [ms]\")\n",
    "ax.set_xlabel(\"channel\")\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf09766",
   "metadata": {},
   "source": [
    "This helps to visualize the slight time-offsets of each array element in receiving the echoes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944bb0f9",
   "metadata": {},
   "source": [
    "## Image reconstruction\n",
    "\n",
    "In multi-plane-wave imaging, each pulse-echo image is constructed separately, then added together.\n",
    "\n",
    "Similar to the focused-pulse `109-ultrasound-imaging-scanline.ipynb` notebook, this notebook demodulates the RF signals to I/Q and then beamforms to create each pulse-echo frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9835d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_signals, _ = demodulate.demodulate_rf_to_iq(\n",
    "    rf_signals,\n",
    "    freq_sampling,\n",
    "    freq_carrier=TONE_CENTER_FREQUENCY,\n",
    "    bandwidth=TRANSDUCER_6DB_PULSE_ECHO_FRACTIONAL_BANDWIDTH,\n",
    ")\n",
    "\n",
    "assert iq_signals.shape == rf_signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664cbb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam-form I/Q signals into an image\n",
    "\n",
    "assert len(scenario.sources) == 1\n",
    "source = scenario.sources[0]\n",
    "assert isinstance(source, ndk.sources.PhasedArraySource)\n",
    "pitch = source.pitch\n",
    "width = source.element_width\n",
    "empirical_pitch = np.linalg.norm(np.diff(results[0].shot.receiver_coordinates, axis=0), axis=1)\n",
    "np.testing.assert_allclose(empirical_pitch, pitch, rtol=1e-2)\n",
    "\n",
    "# Generate an image at the scenario grid\n",
    "# NOTE: .mesh uses different x/y space\n",
    "x_mesh, y_mesh = results[0].shot.grid.space.mesh\n",
    "\n",
    "# Switch to imaging convention: x for parallel-to-array, z for depth\n",
    "imaging_x_mesh = y_mesh + scenario.origin[1]\n",
    "imaging_z_mesh = x_mesh + scenario.origin[0]\n",
    "\n",
    "iq_signals_beamformed_list = []\n",
    "for idx, tilt_angle in enumerate(TILT_ANGLES_DEG):\n",
    "    iq_signals_beamformed = beamform.beamform_delay_and_sum(\n",
    "        iq_signals[:, :, idx],\n",
    "        x=imaging_x_mesh,\n",
    "        z=imaging_z_mesh,\n",
    "        pitch=pitch,\n",
    "        tx_delays=element_delays_list[idx],\n",
    "        freq_sampling=freq_sampling,\n",
    "        freq_carrier=TONE_CENTER_FREQUENCY,\n",
    "        f_number=None,\n",
    "        width=width,\n",
    "        bandwidth=TRANSDUCER_6DB_PULSE_ECHO_FRACTIONAL_BANDWIDTH,\n",
    "        speed_sound=SPEED_OF_SOUND_WATER,  # water\n",
    "    )\n",
    "    iq_signals_beamformed_list.append(iq_signals_beamformed)\n",
    "\n",
    "iq_signals_beamformed_compound = np.stack(iq_signals_beamformed_list, axis=-1)\n",
    "iq_signals_beamformed_compound.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37712d",
   "metadata": {},
   "source": [
    "## Visualize reconstructed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bdea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ultrasound_image(x_mesh, z_mesh, iq_signals_bf, db=40):\n",
    "    plt.pcolormesh(\n",
    "        x_mesh,\n",
    "        z_mesh,\n",
    "        util.log_compress(iq_signals_bf, db),\n",
    "        cmap='gray',\n",
    "    )\n",
    "    cbar = plt.colorbar(ticks=[0, 1])\n",
    "    cbar.ax.set_yticklabels([f\"-{db} dB\", \"0 dB\"])  # horizontal colorbar\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.gca().invert_yaxis()  # Invert the y-axis to flip the image vertically\n",
    "    plt.title('Log-compressed image')\n",
    "    plt.xlabel('[m]')\n",
    "    plt.ylabel('[m]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3250c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_VIS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18450af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (imaging_z_mesh > 0.02).all(axis=1)\n",
    "\n",
    "plot_ultrasound_image(\n",
    "    imaging_x_mesh[mask],\n",
    "    imaging_z_mesh[mask],\n",
    "    iq_signals_beamformed_compound[mask, :, len(TILT_ANGLES_DEG) // 2],\n",
    "    db=DB_VIS\n",
    ")\n",
    "plt.title(\"Single pulse-echo image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b0e2d",
   "metadata": {},
   "source": [
    "A single plane-wave pulse is unfocused, so the image is blurry. On the other hand, it sonicates a larger area than a focused ultrasound beam (a.k.a. \"scan line\"), so it includes both the center circle and the right circle (blurrily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c61f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ultrasound_image(\n",
    "    imaging_x_mesh[mask],\n",
    "    imaging_z_mesh[mask],\n",
    "    iq_signals_beamformed_compound[mask].sum(axis=-1),\n",
    "    db=DB_VIS\n",
    ")\n",
    "plt.title(\"Compound image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246eb52e",
   "metadata": {},
   "source": [
    "Compounding multiple plane waves improves the image focus.\n",
    "\n",
    "The speckles in the image are a normal part of B-mode imaging.\n",
    "Additionally, the phantom on the right experiences a slight \"shadow,\" because not all of the plane waves reach it. If we increase the width of the array so that the plane waves are wider, we would get better coverage of the phantom on the right."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
